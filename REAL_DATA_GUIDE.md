# ğŸš€ HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng Dá»¯ Liá»‡u Tháº­t tá»« TopCV

## âœ¨ ÄÃ£ HoÃ n ThÃ nh

Há»‡ thá»‘ng Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘á»ƒ sá»­ dá»¥ng **dá»¯ liá»‡u tháº­t tá»« TopCV** thay vÃ¬ fake data.

### ğŸ“Š Dataset Hiá»‡n Táº¡i
- **TÃªn**: "TopCV IT Jobs - Real Data (2026-01-30)"
- **Sá»‘ lÆ°á»£ng**: 36 jobs tháº­t Ä‘Æ°á»£c crawler tá»« TopCV
- **Nguá»“n**: https://www.topcv.vn/tim-viec-lam-it-phan-mem-c10026

## ğŸ”„ CÃ¡ch Cáº­p Nháº­t Dá»¯ Liá»‡u Má»›i

### Option 1: Cháº¡y Pipeline Tá»± Äá»™ng (Khuyáº¿n nghá»‹)

**Windows PowerShell:**
```powershell
.\run_full_pipeline.ps1
```

Pipeline nÃ y sáº½ tá»± Ä‘á»™ng:
1. ğŸ“¡ Crawl job listings tá»« TopCV (10 pages)
2. âš™ï¸ Process salary data
3. ğŸ’¾ Import vÃ o database

### Option 2: Cháº¡y Tá»«ng BÆ°á»›c Thá»§ CÃ´ng

```powershell
# Step 1: Crawl dá»¯ liá»‡u tá»« TopCV
python src/crawler/topcv_crawler.py

# Step 2: Process salary data
python src/processing/salary_parser.py

# Step 3: Import vÃ o database
python import_to_db.py
```

## ğŸ“ Cáº¥u TrÃºc Dá»¯ Liá»‡u

```
data/
â”œâ”€â”€ raw/                    # Dá»¯ liá»‡u thÃ´ tá»« crawler
â”‚   â””â”€â”€ topcv_jobs_*.csv   # Files crawled tá»« TopCV
â”œâ”€â”€ processed/              # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”‚   â””â”€â”€ processed_*.csv    # Files Ä‘Ã£ parse salary
â””â”€â”€ jobs.db                 # SQLite database (dá»¯ liá»‡u tháº­t)
```

## ğŸ¯ CÃ¡c ThÃ nh Pháº§n

### 1. Crawler (`src/crawler/topcv_crawler.py`)
- Crawl job listings tá»« TopCV
- LÆ°u vÃ o `data/raw/topcv_jobs_*.csv`
- Máº·c Ä‘á»‹nh: 10 pages (~100-200 jobs)

### 2. Salary Parser (`src/processing/salary_parser.py`)
- Parse salary strings (VND, USD)
- Chuyá»ƒn Ä‘á»•i sang triá»‡u VND
- TÃ­nh average salary
- Output: `data/processed/processed_*.csv`

### 3. Database Importer (`import_to_db.py`)
- XÃ³a dá»¯ liá»‡u cÅ©
- Import dá»¯ liá»‡u má»›i vÃ o SQLite
- Äáº·t tÃªn dataset vá»›i timestamp

## ğŸŒ Xem Káº¿t Quáº£

1. **Khá»Ÿi Ä‘á»™ng backend** (náº¿u chÆ°a cháº¡y):
   ```powershell
   python -m uvicorn backend.main:app --host 127.0.0.1 --port 8081 --reload
   ```

2. **Truy cáº­p web app**:
   - Frontend: http://localhost:5174
   - API: http://localhost:8081/api/jobs

3. **Refresh browser** Ä‘á»ƒ tháº¥y dá»¯ liá»‡u tháº­t tá»« TopCV

## ğŸ“Š API Endpoints vá»›i Dá»¯ Liá»‡u Tháº­t

```bash
# Xem táº¥t cáº£ jobs
GET http://localhost:8081/api/jobs

# Analytics - Salary by location
GET http://localhost:8081/api/analytics/by_location

# Analytics - Salary by level
GET http://localhost:8081/api/analytics/by_level

# Analytics - Salary distribution
GET http://localhost:8081/api/analytics/salary_distribution
```

## âš™ï¸ TÃ¹y Chá»‰nh

### Crawl nhiá»u pages hÆ¡n
Edit `src/crawler/topcv_crawler.py`:
```python
num_pages = 20  # Thay Ä‘á»•i tá»« 10 sang 20
```

### Crawl tá»« nguá»“n khÃ¡c
- ThÃªm crawler má»›i trong `src/crawler/`
- Follow pattern cá»§a `topcv_crawler.py`
- Dataset name sáº½ tá»± Ä‘á»™ng cáº­p nháº­t

## ğŸ” Kiá»ƒm Tra Dá»¯ Liá»‡u

```powershell
# Xem sá»‘ lÆ°á»£ng jobs trong database
python -c "from backend.database import SessionLocal; from backend.models import Job; print(f'Total jobs: {SessionLocal().query(Job).count()}')"

# Xem file crawled má»›i nháº¥t
Get-ChildItem data/raw/*.csv | Sort-Object LastWriteTime -Descending | Select-Object -First 1

# Xem file processed má»›i nháº¥t
Get-ChildItem data/processed/*.csv | Sort-Object LastWriteTime -Descending | Select-Object -First 1
```

## ğŸ’¡ Tips

1. **Crawl Ä‘á»‹nh ká»³**: Cháº¡y pipeline hÃ ng ngÃ y Ä‘á»ƒ cáº­p nháº­t data má»›i
2. **Backup data**: File CSV trong `data/raw/` lÃ  backup cá»§a dá»¯ liá»‡u Ä‘Ã£ crawl
3. **Dataset naming**: Má»—i láº§n import sáº½ tá»± Ä‘á»™ng Ä‘áº·t tÃªn vá»›i timestamp
4. **Error handling**: Crawler sáº½ bá» qua jobs lá»—i vÃ  tiáº¿p tá»¥c crawl

## ğŸš¨ Troubleshooting

### Crawler khÃ´ng láº¥y Ä‘Æ°á»£c data
- Kiá»ƒm tra internet connection
- Website cÃ³ thá»ƒ Ä‘Ã£ thay Ä‘á»•i cáº¥u trÃºc HTML
- Xem log trong console Ä‘á»ƒ debug

### Import lá»—i
- Äáº£m báº£o file processed tá»“n táº¡i trong `data/processed/`
- Check format cá»§a CSV file
- Xem error message trong console

### Backend khÃ´ng hiá»ƒn thá»‹ data
- Restart backend server
- Clear browser cache (Ctrl+F5)
- Check API endpoint tráº£ vá» data: http://localhost:8081/api/jobs

## ğŸ“ Ghi ChÃº

- **Fake data Ä‘Ã£ bá»‹ xÃ³a**: Database hiá»‡n chá»‰ chá»©a dá»¯ liá»‡u tháº­t tá»« TopCV
- **Source tracking**: Má»—i job cÃ³ field `source` Ä‘á»ƒ biáº¿t nguá»“n data
- **Timestamp**: Field `crawled_at` ghi láº¡i thá»i gian crawl
